{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Datasets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  (138, 10)\n",
      "labels:  138\n",
      "static: 22, move: 24, rot: 21, frot: 21, light: 23, dynamiclight: 22, unknown: 5\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "INIT_PATH = '../'\n",
    "TRAIN_RATIO = 0.7\n",
    "AMOUNT_OF_PARAMETERS = 7\n",
    "\n",
    "dataset = []\n",
    "\"\"\"\n",
    "static: 1,0,0,0,0,0,0\n",
    "move: 0,1,0,0,0,0,0\n",
    "rot: 0,0,1,0,0,0,0\n",
    "frot: 0,0,0,1,0,0,0\n",
    "light: 0,0,0,0,1,0,0\n",
    "dynamiclight: 0,0,0,0,0,1,0\n",
    "unknown: 0,0,0,0,0,0,1\n",
    "\n",
    "\"\"\"\n",
    "definition = ['static', 'move', 'rot', 'frot', 'light', 'dynamiclight','unknown']\n",
    "\n",
    "def normalize(dataset):\n",
    "    datasetTmp = np.copy(dataset)\n",
    "    maxx = np.max(dataset, axis=0)\n",
    "    minn = np.min(dataset, axis=0)\n",
    "    rangee = maxx - minn\n",
    "    datasetTmp -= minn\n",
    "    datasetTmp /= rangee\n",
    "    return datasetTmp\n",
    "\n",
    "def loadDataset(path):\n",
    "    dataset = (genfromtxt(INIT_PATH + path, delimiter=','))[1:,:]\n",
    "    dataset = normalize(dataset)\n",
    "    trainingAmount = int(TRAIN_RATIO * dataset.shape[0])\n",
    "    training_dataset = dataset[0:trainingAmount,:]\n",
    "    test_dataset = dataset[trainingAmount:,:]\n",
    "    print(\"data: \", dataset.shape)\n",
    "    return training_dataset.astype(float), test_dataset.astype(float)\n",
    "\n",
    "def loadLabel(path):\n",
    "#     labels = pickle.load(INIT_PATH + path)\n",
    "    with open(INIT_PATH + path, 'rb') as handle:\n",
    "        labels = pickle.load(handle)\n",
    "    ###### TEMPORALLY\n",
    "    del labels[-1]\n",
    "    ######\n",
    "    trainingAmount = int(TRAIN_RATIO * len(labels))\n",
    "    print(\"labels: \", len(labels))\n",
    "    training_labels = np.zeros((trainingAmount, AMOUNT_OF_PARAMETERS))\n",
    "    test_labels = np.zeros((len(labels) - trainingAmount, AMOUNT_OF_PARAMETERS))\n",
    "    label_counter = 0\n",
    "    per_label = [0] * AMOUNT_OF_PARAMETERS\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        tmp = np.zeros((1,AMOUNT_OF_PARAMETERS))\n",
    "        if (label == \"static\"):\n",
    "            tmp[0,0] = 1\n",
    "            per_label[0] += 1\n",
    "        elif (label == \"move\"):\n",
    "            tmp[0,1] = 1\n",
    "            per_label[1] += 1\n",
    "        elif (label == \"rot\"):\n",
    "            tmp[0,2] = 1\n",
    "            per_label[2] += 1            \n",
    "        elif (label == \"frot\"):\n",
    "            tmp[0,3] = 1\n",
    "            per_label[3] += 1\n",
    "        elif (label == \"light\"):\n",
    "            tmp[0,4] = 1\n",
    "            per_label[4] += 1\n",
    "        elif (label == \"dynamiclight\"):\n",
    "            tmp[0,5] = 1\n",
    "            per_label[5] += 1\n",
    "        else:\n",
    "            tmp[0,6] = 1\n",
    "            per_label[6] += 1\n",
    "        if(label_counter < trainingAmount):\n",
    "            training_labels[label_counter,:] = tmp\n",
    "        else:\n",
    "            test_labels[label_counter - trainingAmount,:] = tmp\n",
    "        label_counter += 1\n",
    "    print(\", \".join([definition[i] + \": \" + str(per_label[i]) for i in range (len(per_label))]))\n",
    "    return training_labels, test_labels\n",
    "training_dataset, test_dataset = loadDataset(\"FrankensteinFullForm.csv\")\n",
    "training_labels, test_labels = loadLabel(\"LabelFrankensteinFullForm.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 10)\n",
      "(42, 10)\n",
      "(96, 7)\n",
      "(42, 7)\n"
     ]
    }
   ],
   "source": [
    "print(training_dataset.shape)\n",
    "print(test_dataset.shape)\n",
    "print(training_labels.shape)\n",
    "print(test_labels.shape)\n",
    "# training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.1092296 , 0.16715095, 0.52934208, 0.21504995, 0.23992044,\n",
      "       0.32241417, 0.31384785, 0.05240026, 0.41536227, 0.12281167]), array([1., 0., 0., 0., 0., 0., 0.]))\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__( self, data, labels, transform=None, data_dir=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __getitem__(self,index):\n",
    "        singleData = self.data[index]\n",
    "        singleLabel = self.labels[index]\n",
    "        return (singleData, singleLabel)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "training_set = Data(training_dataset, training_labels)\n",
    "test_set = Data(test_dataset, test_labels)\n",
    "print(training_set.__getitem__(10))\n",
    "print(training_set.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(training_set, batch_size = 1, shuffle = True)\n",
    "dataiter = iter(trainloader)\n",
    "datum,label = dataiter.next()\n",
    "print(datum.shape)\n",
    "\n",
    "testloader = DataLoader(test_set, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel(\n",
      "  (fc1): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 100)\n",
    "        self.fc2 = nn.Linear(100, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "LRNet = LinearRegressionModel(10,7)\n",
    "# LRNet = LRNet.cuda()\n",
    "print(LRNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion =  nn.MSELoss()\n",
    "# optimizer = optim.SGD(LRNet.parameters(), lr = 0.001, momentum = 0.9)\n",
    "optimizer = optim.SGD(LRNet.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.014\n",
      "[1,    11] loss: 0.059\n",
      "[1,    21] loss: 0.043\n",
      "[1,    31] loss: 0.063\n",
      "[1,    41] loss: 0.085\n",
      "[1,    51] loss: 0.068\n",
      "[1,    61] loss: 0.092\n",
      "[1,    71] loss: 0.068\n",
      "[1,    81] loss: 0.072\n",
      "[1,    91] loss: 0.043\n",
      "[2,     1] loss: 0.014\n",
      "[2,    11] loss: 0.057\n",
      "[2,    21] loss: 0.060\n",
      "[2,    31] loss: 0.094\n",
      "[2,    41] loss: 0.067\n",
      "[2,    51] loss: 0.059\n",
      "[2,    61] loss: 0.070\n",
      "[2,    71] loss: 0.042\n",
      "[2,    81] loss: 0.065\n",
      "[2,    91] loss: 0.097\n",
      "[3,     1] loss: 0.008\n",
      "[3,    11] loss: 0.074\n",
      "[3,    21] loss: 0.038\n",
      "[3,    31] loss: 0.065\n",
      "[3,    41] loss: 0.076\n",
      "[3,    51] loss: 0.081\n",
      "[3,    61] loss: 0.087\n",
      "[3,    71] loss: 0.088\n",
      "[3,    81] loss: 0.036\n",
      "[3,    91] loss: 0.057\n",
      "finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bon/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (3):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputt, labell = data\n",
    "        inputs, labels = Variable(inputt.float()), Variable(labell.float())\n",
    "#         print(inputs)\n",
    "#         print(inputs.double())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = LRNet(inputs)\n",
    "#         if i == 1:\n",
    "#             print('inputs: ',inputs[0])\n",
    "#             print('outputs:', outputs[0])\n",
    "#             print(\"labels:\", labels[0])\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "#         print('loss meme:',loss)\n",
    "        if(i % 10 == 0):\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputToTensor(labels):\n",
    "    # print(labels)\n",
    "    # print(labels.numpy().astype(int))\n",
    "    tmp = labels.numpy().astype(int)\n",
    "    # print([ np.where(r==1)[0][0] for r in tmp ])\n",
    "    tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
    "    tmp = np.array(tmp)\n",
    "    tmp = torch.from_numpy(tmp)\n",
    "    # print(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth :  [0. 0. 0. 0. 0. 1. 0.]\n",
      "Predicted torch :  tensor([ 4])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-588ada56233a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted torch : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# print('Predicted :',' '.join('%5s'% classes[int(predicted[j])] for j in range(4) ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-588ada56233a>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted torch : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# print('Predicted :',' '.join('%5s'% classes[int(predicted[j])] for j in range(4) ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "definition = ['static', 'move', 'rot', 'frot', 'light', 'dynamiclight','unknown']\n",
    "\n",
    "\"\"\"\n",
    "static: 1,0,0,0,0,0,0\n",
    "move: 0,1,0,0,0,0,0\n",
    "rot: 0,0,1,0,0,0,0\n",
    "frot: 0,0,0,1,0,0,0\n",
    "light: 0,0,0,0,1,0,0\n",
    "dynamiclight: 0,0,0,0,0,1,0\n",
    "unknown: 0,0,0,0,0,0,1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "dataiter  = iter(testloader)\n",
    "test_data,labels = dataiter.next()\n",
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(test_data))\n",
    "# print labels\n",
    "print(\"Ground truth : \", ' '.join(np.array2string(x.numpy()) for x in labels))\n",
    "# print('dimensions : ',' '.join(x.numpy().shape for x in images))\n",
    "# imshow(torchvision.utils.make_grid(test_data))\n",
    "\n",
    "outputs = LRNet(Variable(test_data.float()))\n",
    "# print('outputs:',outputs)\n",
    "_,predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted torch : ',predicted )\n",
    "print('Predicted : ',' '.join(definition[predicted[i]] for i in range(1)))\n",
    "\n",
    "# print('Predicted :',' '.join('%5s'% classes[int(predicted[j])] for j in range(4) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCompare(data):\n",
    "#     print(data.shape)\n",
    "    arr = np.ones(data.shape[0])\n",
    "    for i in range(arr.shape[0]):\n",
    "        if(np.array_equal(data[i].numpy(),np.array([1,0]))):\n",
    "            arr[i] = 0\n",
    "    result = torch.from_numpy(arr).float() \n",
    "#     print(result)\n",
    "    return  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : tensor(0)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    i += 1\n",
    "    images,labels = data\n",
    "#     print('raw label : ',labels)\n",
    "    outputs = LRNet(Variable(images.float()))\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "#     labels = outputToTensor(labels)\n",
    "    total += labels.size(0)\n",
    "#     print('predicted : ',predicted)\n",
    "    compared = toCompare(labels.cpu().float()) == predicted.float()\n",
    "#     print('compare result : ', compared)\n",
    "    correct += (compared).sum()    \n",
    "print('Accuracy :',(correct/total*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
