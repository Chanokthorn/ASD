{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"FrankensteinFullForm.csv\")\n",
    "# df = df.as_matrix()\n",
    "# print(df.shape)\n",
    "# labels = pd.read_csv(\"LabelFrankensteinFullForm.csv\", header = None)\n",
    "# labels = labels.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy import genfromtxt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "AMOUNT_OF_CLASSES = 7\n",
    "\n",
    "\n",
    "def loadDataset(path):\n",
    "    inputdataset = (genfromtxt(path, delimiter=','))[1:,:]\n",
    "    dataset = normalize(inputdataset)\n",
    "    trainingAmount = int(TRAIN_RATIO * dataset.shape[0])\n",
    "    training_dataset = dataset[0:trainingAmount,:]\n",
    "    test_dataset = dataset[trainingAmount:,:]\n",
    "    print(\"data: \", dataset.shape)\n",
    "    return training_dataset.astype(float), test_dataset.astype(float)\n",
    "\n",
    "def loadLabel(data_path, labels_path):\n",
    "    dataset = (genfromtxt(data_path, delimiter=','))[1:,:]\n",
    "#     dataset = normalize(dataset)\n",
    "    trainingAmount = int(TRAIN_RATIO * dataset.shape[0])\n",
    "    #     labels = pickle.load(INIT_PATH + path)\n",
    "    with open(labels_path, 'rb') as handle:\n",
    "        labels = pickle.load(handle)\n",
    "    ###### TEMPORARY\n",
    "    del labels[-1]\n",
    "    ######\n",
    "    all_labels = np.zeros((len(labels), AMOUNT_OF_CLASSES))\n",
    "#     training_labels = np.zeros((trainingAmount, AMOUNT_OF_CLASSES))\n",
    "#     test_labels = np.zeros((len(labels) - trainingAmount, AMOUNT_OF_CLASSES))\n",
    "    label_counter = 0\n",
    "    per_label = [0] * AMOUNT_OF_CLASSES\n",
    "#     print(labels)\n",
    "    for label in labels:\n",
    "        tmp = np.zeros((1,AMOUNT_OF_CLASSES))\n",
    "        if (label == \"static\"):\n",
    "            tmp[0,0] = 1\n",
    "            per_label[0] += 1\n",
    "        elif (label == \"move\"):\n",
    "            tmp[0,1] = 1\n",
    "            per_label[1] += 1\n",
    "        elif (label == \"rot\"):\n",
    "            tmp[0,2] = 1\n",
    "            per_label[2] += 1            \n",
    "        elif (label == \"frot\"):\n",
    "            tmp[0,3] = 1\n",
    "            per_label[3] += 1\n",
    "        elif (label == \"light\"):\n",
    "            tmp[0,4] = 1\n",
    "            per_label[4] += 1\n",
    "        elif (label == \"dynamiclight\"):\n",
    "            tmp[0,5] = 1\n",
    "            per_label[5] += 1\n",
    "        else:\n",
    "            tmp[0,6] = 1\n",
    "            per_label[6] += 1\n",
    "        all_labels[label_counter,:] = tmp\n",
    "#         if(label_counter < trainingAmount):\n",
    "#             training_labels[label_counter,:] = tmp\n",
    "#         else:\n",
    "#             test_labels[label_counter - trainingAmount,:] = tmp\n",
    "        label_counter += 1\n",
    "    dataset, all_labels = shuffle(dataset, all_labels, random_state=0)\n",
    "    return assignData(dataset, all_labels)\n",
    "    \n",
    "#     train_dataset = dataset[0:trainingAmount,:]\n",
    "#     test_dataset = dataset[trainingAmount:,:]\n",
    "#     print(\"data: \", dataset.shape)\n",
    "    \n",
    "#     train_labels = all_labels[:trainingAmount,:]\n",
    "#     test_labels = all_labels[trainingAmount:,:]\n",
    "    \n",
    "#     print(\", \".join([definition[i] + \": \" + str(per_label[i]) for i in range (len(per_label))]))\n",
    "#     return train_dataset.astype(float), test_dataset.astype(float),train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignData(data,labels):\n",
    "    UNKNOWN_AMOUNT = 5\n",
    "    train_amount = int(data.shape[0] * TRAIN_RATIO)\n",
    "    AMOUNT_PER_CLASS = int((data.shape[0] - UNKNOWN_AMOUNT) * TRAIN_RATIO)\n",
    "    class_count = [0] * train_amount\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for i in range (data.shape[0]):\n",
    "        if(len(train_data) == train_amount):\n",
    "            test_data.append(data[i])\n",
    "            test_labels.append(labels[i])\n",
    "        else:\n",
    "            index = np.argmax(data[i])\n",
    "            if(index == AMOUNT_OF_CLASSES - 1):\n",
    "                test_data.append(data[i])\n",
    "                test_labels.append(labels[i])\n",
    "            if( class_count[index] < AMOUNT_PER_CLASS) :\n",
    "                train_data.append(data[i])\n",
    "                train_labels.append(labels[i])\n",
    "                class_count[index] += 1\n",
    "            else:\n",
    "                test_data.append(data[i])\n",
    "                test_labels.append(abels[i])\n",
    "    return np.asarray(train_data), np.asarray(test_data), np.asarray(train_labels), np.asarray(test_labels)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(110, 10)\n",
      "(28, 10)\n",
      "(110, 7)\n",
      "(28, 7)\n",
      "[19. 16. 17. 17. 18. 18.  5.]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = loadLabel(\"../unnormres.csv\",\"LabelFrankensteinFullForm.p\")\n",
    "print(train_labels.dtype)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "# print(train_labels)\n",
    "print(np.sum(train_labels,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../unnormFrankensteinFullForm.csv\") as f:\n",
    "with open(\"../unnormres.csv\") as f:\n",
    "    lines = (line for line in f if not line.startswith('#'))\n",
    "    dataset = np.loadtxt(lines, delimiter=',', skiprows=1)\n",
    "definition = ['static', 'move', 'rot', 'frot', 'light', 'dynamiclight','unknown']\n",
    "scaler = StandardScaler(copy=True)\n",
    "scaler.fit(dataset)\n",
    "\n",
    "def normalize(dataset):\n",
    "    datasetTmp = scaler.transform(dataset)\n",
    "    return datasetTmp\n",
    "dataset = normalize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation='linear', input_dim=10))\n",
    "model.add(Dense(128,activation='linear'))\n",
    "model.add(Dense(256, activation='linear'))\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(Dense(64, activation='linear'))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opti = optimizers.SGD(lr=0.0002, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "opti =optimizers.Adam(beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy'])\n",
    "# model.compile(loss='MSE', optimizer=opti, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.3669 - acc: 0.8571\n",
      "Epoch 2/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3334 - acc: 0.8688\n",
      "Epoch 3/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2626 - acc: 0.8883\n",
      "Epoch 4/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2506 - acc: 0.9026\n",
      "Epoch 5/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2631 - acc: 0.8922\n",
      "Epoch 6/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2506 - acc: 0.8974\n",
      "Epoch 7/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2200 - acc: 0.9065\n",
      "Epoch 8/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2323 - acc: 0.8974\n",
      "Epoch 9/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2451 - acc: 0.8961\n",
      "Epoch 10/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2334 - acc: 0.8961\n",
      "Epoch 11/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.8961\n",
      "Epoch 12/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2060 - acc: 0.9130\n",
      "Epoch 13/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2361 - acc: 0.8935\n",
      "Epoch 14/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2216 - acc: 0.9013\n",
      "Epoch 15/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2139 - acc: 0.9130\n",
      "Epoch 16/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2154 - acc: 0.9104\n",
      "Epoch 17/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2136 - acc: 0.9065\n",
      "Epoch 18/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2164 - acc: 0.9104\n",
      "Epoch 19/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2026 - acc: 0.9143\n",
      "Epoch 20/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1975 - acc: 0.9221\n",
      "Epoch 21/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2103 - acc: 0.9026\n",
      "Epoch 22/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1913 - acc: 0.9143\n",
      "Epoch 23/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1970 - acc: 0.9169\n",
      "Epoch 24/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.9117\n",
      "Epoch 25/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2210 - acc: 0.9117\n",
      "Epoch 26/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2021 - acc: 0.9117\n",
      "Epoch 27/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2122 - acc: 0.9065\n",
      "Epoch 28/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1944 - acc: 0.9169\n",
      "Epoch 29/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1862 - acc: 0.9234\n",
      "Epoch 30/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1730 - acc: 0.9299\n",
      "Epoch 31/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2023 - acc: 0.9130\n",
      "Epoch 32/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1869 - acc: 0.9247\n",
      "Epoch 33/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1870 - acc: 0.9130\n",
      "Epoch 34/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1833 - acc: 0.9234\n",
      "Epoch 35/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1765 - acc: 0.9260\n",
      "Epoch 36/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1773 - acc: 0.9208\n",
      "Epoch 37/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1793 - acc: 0.9299\n",
      "Epoch 38/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1759 - acc: 0.9299\n",
      "Epoch 39/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1820 - acc: 0.9247\n",
      "Epoch 40/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1838 - acc: 0.9221\n",
      "Epoch 41/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1746 - acc: 0.9338\n",
      "Epoch 42/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1654 - acc: 0.9325\n",
      "Epoch 43/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 0.9416\n",
      "Epoch 44/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1751 - acc: 0.9325\n",
      "Epoch 45/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1650 - acc: 0.9260\n",
      "Epoch 46/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1626 - acc: 0.9286\n",
      "Epoch 47/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1624 - acc: 0.9364\n",
      "Epoch 48/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1708 - acc: 0.9273\n",
      "Epoch 49/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1544 - acc: 0.9390\n",
      "Epoch 50/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1689 - acc: 0.9325\n",
      "Epoch 51/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1538 - acc: 0.9286\n",
      "Epoch 52/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1518 - acc: 0.9351\n",
      "Epoch 53/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1583 - acc: 0.9351\n",
      "Epoch 54/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1578 - acc: 0.9325\n",
      "Epoch 55/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1676 - acc: 0.9195\n",
      "Epoch 56/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1510 - acc: 0.9338\n",
      "Epoch 57/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1535 - acc: 0.9364\n",
      "Epoch 58/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1656 - acc: 0.9312\n",
      "Epoch 59/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1676 - acc: 0.9286\n",
      "Epoch 60/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1497 - acc: 0.9416\n",
      "Epoch 61/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1441 - acc: 0.9390\n",
      "Epoch 62/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1441 - acc: 0.9403\n",
      "Epoch 63/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1358 - acc: 0.9494\n",
      "Epoch 64/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1616 - acc: 0.9312\n",
      "Epoch 65/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1421 - acc: 0.9390\n",
      "Epoch 66/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1403 - acc: 0.9325\n",
      "Epoch 67/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1510 - acc: 0.9390\n",
      "Epoch 68/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1558 - acc: 0.9403\n",
      "Epoch 69/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1539 - acc: 0.9351\n",
      "Epoch 70/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1418 - acc: 0.9455\n",
      "Epoch 71/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1564 - acc: 0.9260\n",
      "Epoch 72/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1519 - acc: 0.9377\n",
      "Epoch 73/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1550 - acc: 0.9390\n",
      "Epoch 74/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1367 - acc: 0.9403\n",
      "Epoch 75/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1326 - acc: 0.9442\n",
      "Epoch 76/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9416\n",
      "Epoch 77/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1371 - acc: 0.9377\n",
      "Epoch 78/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1490 - acc: 0.9390\n",
      "Epoch 79/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.2014 - acc: 0.9130\n",
      "Epoch 80/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1697 - acc: 0.9221\n",
      "Epoch 81/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1453 - acc: 0.9429\n",
      "Epoch 82/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1572 - acc: 0.9325\n",
      "Epoch 83/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1502 - acc: 0.9351\n",
      "Epoch 84/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1492 - acc: 0.9364\n",
      "Epoch 85/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1272 - acc: 0.9338\n",
      "Epoch 86/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1439 - acc: 0.9416\n",
      "Epoch 87/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1362 - acc: 0.9416\n",
      "Epoch 88/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1465 - acc: 0.9377\n",
      "Epoch 89/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1155 - acc: 0.9532\n",
      "Epoch 90/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1232 - acc: 0.9519\n",
      "Epoch 91/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1468 - acc: 0.9234\n",
      "Epoch 92/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1681 - acc: 0.9312\n",
      "Epoch 93/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1311 - acc: 0.9571\n",
      "Epoch 94/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1325 - acc: 0.9468\n",
      "Epoch 95/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1331 - acc: 0.9481\n",
      "Epoch 96/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1325 - acc: 0.9429\n",
      "Epoch 97/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1538 - acc: 0.9299\n",
      "Epoch 98/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1357 - acc: 0.9403\n",
      "Epoch 99/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1210 - acc: 0.9494\n",
      "Epoch 100/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1322 - acc: 0.9455\n",
      "Epoch 101/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1225 - acc: 0.9455\n",
      "Epoch 102/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1251 - acc: 0.9429\n",
      "Epoch 103/400\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.1178 - acc: 0.9481\n",
      "Epoch 104/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1561 - acc: 0.9377\n",
      "Epoch 105/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1477 - acc: 0.9429\n",
      "Epoch 106/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1198 - acc: 0.9584\n",
      "Epoch 107/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1309 - acc: 0.9377\n",
      "Epoch 108/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1417 - acc: 0.9390\n",
      "Epoch 109/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1415 - acc: 0.9390\n",
      "Epoch 110/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1191 - acc: 0.9506\n",
      "Epoch 111/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1444 - acc: 0.9429\n",
      "Epoch 112/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1277 - acc: 0.9377\n",
      "Epoch 113/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1547 - acc: 0.9286\n",
      "Epoch 114/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9597\n",
      "Epoch 115/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1158 - acc: 0.9455\n",
      "Epoch 116/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1270 - acc: 0.9455\n",
      "Epoch 117/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1235 - acc: 0.9558\n",
      "Epoch 118/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1152 - acc: 0.9519\n",
      "Epoch 119/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1119 - acc: 0.9506\n",
      "Epoch 120/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1248 - acc: 0.9455\n",
      "Epoch 121/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1437 - acc: 0.9364\n",
      "Epoch 122/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1271 - acc: 0.9597\n",
      "Epoch 123/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1211 - acc: 0.9519\n",
      "Epoch 124/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1604 - acc: 0.9312\n",
      "Epoch 125/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1768 - acc: 0.9260\n",
      "Epoch 126/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1822 - acc: 0.9299\n",
      "Epoch 127/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1447 - acc: 0.9325\n",
      "Epoch 128/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1346 - acc: 0.9455\n",
      "Epoch 129/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1207 - acc: 0.9481\n",
      "Epoch 130/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9545\n",
      "Epoch 131/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1215 - acc: 0.9506\n",
      "Epoch 132/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1435 - acc: 0.9351\n",
      "Epoch 133/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1321 - acc: 0.9455\n",
      "Epoch 134/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1118 - acc: 0.9468\n",
      "Epoch 135/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1254 - acc: 0.9506\n",
      "Epoch 136/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1062 - acc: 0.9532\n",
      "Epoch 137/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9584\n",
      "Epoch 138/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9506\n",
      "Epoch 139/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1272 - acc: 0.9429\n",
      "Epoch 140/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 0.9558\n",
      "Epoch 141/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9468\n",
      "Epoch 142/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1340 - acc: 0.9429\n",
      "Epoch 143/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1175 - acc: 0.9532\n",
      "Epoch 144/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1274 - acc: 0.9442\n",
      "Epoch 145/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9481\n",
      "Epoch 146/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1367 - acc: 0.9416\n",
      "Epoch 147/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1408 - acc: 0.9481\n",
      "Epoch 148/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1399 - acc: 0.9351\n",
      "Epoch 149/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1288 - acc: 0.9442\n",
      "Epoch 150/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1244 - acc: 0.9506\n",
      "Epoch 151/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1199 - acc: 0.9429\n",
      "Epoch 152/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 0.9494\n",
      "Epoch 153/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1286 - acc: 0.9506\n",
      "Epoch 154/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1155 - acc: 0.9532\n",
      "Epoch 155/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9532\n",
      "Epoch 156/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1162 - acc: 0.9519\n",
      "Epoch 157/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1114 - acc: 0.9506\n",
      "Epoch 158/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1091 - acc: 0.9584\n",
      "Epoch 159/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9468\n",
      "Epoch 160/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1108 - acc: 0.9571\n",
      "Epoch 161/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9545\n",
      "Epoch 162/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9403\n",
      "Epoch 163/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1326 - acc: 0.9429\n",
      "Epoch 164/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1805 - acc: 0.9182\n",
      "Epoch 165/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1319 - acc: 0.9481\n",
      "Epoch 166/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1228 - acc: 0.9532\n",
      "Epoch 167/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1200 - acc: 0.9519\n",
      "Epoch 168/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1185 - acc: 0.9532\n",
      "Epoch 169/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1296 - acc: 0.9481\n",
      "Epoch 170/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1113 - acc: 0.9558\n",
      "Epoch 171/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1046 - acc: 0.9662\n",
      "Epoch 172/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1200 - acc: 0.9455\n",
      "Epoch 173/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1084 - acc: 0.9532\n",
      "Epoch 174/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1067 - acc: 0.9545\n",
      "Epoch 175/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9584\n",
      "Epoch 176/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1081 - acc: 0.9506\n",
      "Epoch 177/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1157 - acc: 0.9494\n",
      "Epoch 178/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9610\n",
      "Epoch 179/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1093 - acc: 0.9623\n",
      "Epoch 180/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1087 - acc: 0.9519\n",
      "Epoch 181/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1236 - acc: 0.9455\n",
      "Epoch 182/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1210 - acc: 0.9584\n",
      "Epoch 183/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2189 - acc: 0.9221\n",
      "Epoch 184/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1978 - acc: 0.9273\n",
      "Epoch 185/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1378 - acc: 0.9390\n",
      "Epoch 186/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1195 - acc: 0.9481\n",
      "Epoch 187/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1100 - acc: 0.9558\n",
      "Epoch 188/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1292 - acc: 0.9455\n",
      "Epoch 189/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1112 - acc: 0.9558\n",
      "Epoch 190/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1086 - acc: 0.9610\n",
      "Epoch 191/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1147 - acc: 0.9532\n",
      "Epoch 192/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 0.9571\n",
      "Epoch 193/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1074 - acc: 0.9545\n",
      "Epoch 194/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1053 - acc: 0.9584\n",
      "Epoch 195/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1172 - acc: 0.9558\n",
      "Epoch 196/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1001 - acc: 0.9571\n",
      "Epoch 197/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1062 - acc: 0.9610\n",
      "Epoch 198/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1131 - acc: 0.9481\n",
      "Epoch 199/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.9584\n",
      "Epoch 200/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1131 - acc: 0.9532\n",
      "Epoch 201/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1235 - acc: 0.9442\n",
      "Epoch 202/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1177 - acc: 0.9545\n",
      "Epoch 203/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1260 - acc: 0.9468\n",
      "Epoch 204/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1298 - acc: 0.9403\n",
      "Epoch 205/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1296 - acc: 0.9429\n",
      "Epoch 206/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1166 - acc: 0.9455\n",
      "Epoch 207/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1104 - acc: 0.9623\n",
      "Epoch 208/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1086 - acc: 0.9558\n",
      "Epoch 209/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9623\n",
      "Epoch 210/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0957 - acc: 0.9545\n",
      "Epoch 211/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1074 - acc: 0.9571\n",
      "Epoch 212/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1276 - acc: 0.9558\n",
      "Epoch 213/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1113 - acc: 0.9481\n",
      "Epoch 214/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1011 - acc: 0.9584\n",
      "Epoch 215/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 0.9610\n",
      "Epoch 216/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1128 - acc: 0.9494\n",
      "Epoch 217/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1084 - acc: 0.9558\n",
      "Epoch 218/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9623\n",
      "Epoch 219/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1056 - acc: 0.9571\n",
      "Epoch 220/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1221 - acc: 0.9468\n",
      "Epoch 221/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9429\n",
      "Epoch 222/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2119 - acc: 0.9364\n",
      "Epoch 223/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4920 - acc: 0.8857\n",
      "Epoch 224/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1541 - acc: 0.9442\n",
      "Epoch 225/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1410 - acc: 0.9403\n",
      "Epoch 226/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1126 - acc: 0.9494\n",
      "Epoch 227/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1102 - acc: 0.9494\n",
      "Epoch 228/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1101 - acc: 0.9610\n",
      "Epoch 229/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0948 - acc: 0.9610\n",
      "Epoch 230/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1048 - acc: 0.9623\n",
      "Epoch 231/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0951 - acc: 0.9623\n",
      "Epoch 232/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1044 - acc: 0.9584\n",
      "Epoch 233/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1229 - acc: 0.9519\n",
      "Epoch 234/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1168 - acc: 0.9468\n",
      "Epoch 235/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1153 - acc: 0.9545\n",
      "Epoch 236/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1064 - acc: 0.9597\n",
      "Epoch 237/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9532\n",
      "Epoch 238/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1021 - acc: 0.9675\n",
      "Epoch 239/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9571\n",
      "Epoch 240/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1164 - acc: 0.9455\n",
      "Epoch 241/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0991 - acc: 0.9610\n",
      "Epoch 242/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1093 - acc: 0.9519\n",
      "Epoch 243/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1073 - acc: 0.9571\n",
      "Epoch 244/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1302 - acc: 0.9506\n",
      "Epoch 245/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1014 - acc: 0.9649\n",
      "Epoch 246/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1096 - acc: 0.9519\n",
      "Epoch 247/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1036 - acc: 0.9571\n",
      "Epoch 248/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0948 - acc: 0.9623\n",
      "Epoch 249/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1064 - acc: 0.9519\n",
      "Epoch 250/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1040 - acc: 0.9623\n",
      "Epoch 251/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1106 - acc: 0.9571\n",
      "Epoch 252/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9597\n",
      "Epoch 253/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1365 - acc: 0.9442\n",
      "Epoch 254/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1596 - acc: 0.9338\n",
      "Epoch 255/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1062 - acc: 0.9506\n",
      "Epoch 256/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1259 - acc: 0.9506\n",
      "Epoch 257/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0998 - acc: 0.9623\n",
      "Epoch 258/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1420 - acc: 0.9468\n",
      "Epoch 259/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1122 - acc: 0.9558\n",
      "Epoch 260/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1083 - acc: 0.9571\n",
      "Epoch 261/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.9571\n",
      "Epoch 262/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0965 - acc: 0.9597\n",
      "Epoch 263/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1045 - acc: 0.9649\n",
      "Epoch 264/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1018 - acc: 0.9584\n",
      "Epoch 265/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 0.9532\n",
      "Epoch 266/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1085 - acc: 0.9558\n",
      "Epoch 267/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1057 - acc: 0.9545\n",
      "Epoch 268/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1182 - acc: 0.9623\n",
      "Epoch 269/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1039 - acc: 0.9636\n",
      "Epoch 270/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1037 - acc: 0.9519\n",
      "Epoch 271/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9571\n",
      "Epoch 272/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1128 - acc: 0.9532\n",
      "Epoch 273/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1173 - acc: 0.9545\n",
      "Epoch 274/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1168 - acc: 0.9481\n",
      "Epoch 275/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3786 - acc: 0.9208\n",
      "Epoch 276/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.6527 - acc: 0.8779\n",
      "Epoch 277/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1751 - acc: 0.9325\n",
      "Epoch 278/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1298 - acc: 0.9494\n",
      "Epoch 279/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1100 - acc: 0.9571\n",
      "Epoch 280/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1096 - acc: 0.9558\n",
      "Epoch 281/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0946 - acc: 0.9662\n",
      "Epoch 282/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1165 - acc: 0.9494\n",
      "Epoch 283/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1007 - acc: 0.9636\n",
      "Epoch 284/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0948 - acc: 0.9623\n",
      "Epoch 285/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9649\n",
      "Epoch 286/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.9506\n",
      "Epoch 287/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0995 - acc: 0.9558\n",
      "Epoch 288/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9468\n",
      "Epoch 289/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1024 - acc: 0.9597\n",
      "Epoch 290/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1057 - acc: 0.9597\n",
      "Epoch 291/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1098 - acc: 0.9519\n",
      "Epoch 292/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1271 - acc: 0.9429\n",
      "Epoch 293/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1192 - acc: 0.9468\n",
      "Epoch 294/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9545\n",
      "Epoch 295/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1161 - acc: 0.9481\n",
      "Epoch 296/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1059 - acc: 0.9545\n",
      "Epoch 297/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1077 - acc: 0.9545\n",
      "Epoch 298/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1077 - acc: 0.9571\n",
      "Epoch 299/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1056 - acc: 0.9610\n",
      "Epoch 300/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0948 - acc: 0.9649\n",
      "Epoch 301/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 0.9584\n",
      "Epoch 302/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0965 - acc: 0.9623\n",
      "Epoch 303/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1096 - acc: 0.9532\n",
      "Epoch 304/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1343 - acc: 0.9455\n",
      "Epoch 305/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1135 - acc: 0.9455\n",
      "Epoch 306/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9455\n",
      "Epoch 307/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1087 - acc: 0.9558\n",
      "Epoch 308/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1217 - acc: 0.9442\n",
      "Epoch 309/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1093 - acc: 0.9545\n",
      "Epoch 310/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1200 - acc: 0.9519\n",
      "Epoch 311/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9519\n",
      "Epoch 312/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1029 - acc: 0.9532\n",
      "Epoch 313/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9597\n",
      "Epoch 314/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1000 - acc: 0.9597\n",
      "Epoch 315/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1227 - acc: 0.9506\n",
      "Epoch 316/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0973 - acc: 0.9636\n",
      "Epoch 317/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0968 - acc: 0.9662\n",
      "Epoch 318/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0928 - acc: 0.9701\n",
      "Epoch 319/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0935 - acc: 0.9688\n",
      "Epoch 320/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9584\n",
      "Epoch 321/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 0.9584\n",
      "Epoch 322/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1061 - acc: 0.9481\n",
      "Epoch 323/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0976 - acc: 0.9662\n",
      "Epoch 324/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9558\n",
      "Epoch 325/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1171 - acc: 0.9481\n",
      "Epoch 326/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1015 - acc: 0.9506\n",
      "Epoch 327/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1190 - acc: 0.9506\n",
      "Epoch 328/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1509 - acc: 0.9494\n",
      "Epoch 329/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0989 - acc: 0.9688\n",
      "Epoch 330/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1082 - acc: 0.9545\n",
      "Epoch 331/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0955 - acc: 0.9545\n",
      "Epoch 332/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1019 - acc: 0.9545\n",
      "Epoch 333/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1022 - acc: 0.9584\n",
      "Epoch 334/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.9649\n",
      "Epoch 335/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0920 - acc: 0.9649\n",
      "Epoch 336/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0993 - acc: 0.9636\n",
      "Epoch 337/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1117 - acc: 0.9571\n",
      "Epoch 338/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1664 - acc: 0.9429\n",
      "Epoch 339/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1722 - acc: 0.9442\n",
      "Epoch 340/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9506\n",
      "Epoch 341/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0990 - acc: 0.9519\n",
      "Epoch 342/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1006 - acc: 0.9597\n",
      "Epoch 343/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0929 - acc: 0.9610\n",
      "Epoch 344/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1050 - acc: 0.9532\n",
      "Epoch 345/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0970 - acc: 0.9558\n",
      "Epoch 346/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1138 - acc: 0.9481\n",
      "Epoch 347/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 0.9584\n",
      "Epoch 348/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1002 - acc: 0.9545\n",
      "Epoch 349/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0975 - acc: 0.9571\n",
      "Epoch 350/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1222 - acc: 0.9519\n",
      "Epoch 351/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1037 - acc: 0.9545\n",
      "Epoch 352/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0947 - acc: 0.9610\n",
      "Epoch 353/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0957 - acc: 0.9571\n",
      "Epoch 354/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0976 - acc: 0.9623\n",
      "Epoch 355/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1030 - acc: 0.9610\n",
      "Epoch 356/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0880 - acc: 0.9623\n",
      "Epoch 357/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1221 - acc: 0.9571\n",
      "Epoch 358/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1019 - acc: 0.9610\n",
      "Epoch 359/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0997 - acc: 0.9649\n",
      "Epoch 360/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0941 - acc: 0.9623\n",
      "Epoch 361/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.9584\n",
      "Epoch 362/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0977 - acc: 0.9662\n",
      "Epoch 363/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9558\n",
      "Epoch 364/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1386 - acc: 0.9506\n",
      "Epoch 365/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2545 - acc: 0.9221\n",
      "Epoch 366/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1458 - acc: 0.9364\n",
      "Epoch 367/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1191 - acc: 0.9558\n",
      "Epoch 368/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1040 - acc: 0.9584\n",
      "Epoch 369/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1020 - acc: 0.9597\n",
      "Epoch 370/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1019 - acc: 0.9584\n",
      "Epoch 371/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0937 - acc: 0.9675\n",
      "Epoch 372/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0901 - acc: 0.9649\n",
      "Epoch 373/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0992 - acc: 0.9610\n",
      "Epoch 374/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0978 - acc: 0.9597\n",
      "Epoch 375/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9558\n",
      "Epoch 376/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0953 - acc: 0.9649\n",
      "Epoch 377/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9636\n",
      "Epoch 378/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0933 - acc: 0.9597\n",
      "Epoch 379/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1053 - acc: 0.9701\n",
      "Epoch 380/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1020 - acc: 0.9610\n",
      "Epoch 381/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0934 - acc: 0.9597\n",
      "Epoch 382/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1008 - acc: 0.9636\n",
      "Epoch 383/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9610\n",
      "Epoch 384/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1060 - acc: 0.9532\n",
      "Epoch 385/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9584\n",
      "Epoch 386/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1056 - acc: 0.9623\n",
      "Epoch 387/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1149 - acc: 0.9532\n",
      "Epoch 388/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0850 - acc: 0.9649\n",
      "Epoch 389/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1051 - acc: 0.9519\n",
      "Epoch 390/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1110 - acc: 0.9494\n",
      "Epoch 391/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0901 - acc: 0.9610\n",
      "Epoch 392/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.0891 - acc: 0.9636\n",
      "Epoch 393/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9649\n",
      "Epoch 394/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.9584\n",
      "Epoch 395/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1100 - acc: 0.9584\n",
      "Epoch 396/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1059 - acc: 0.9506\n",
      "Epoch 397/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1133 - acc: 0.9442\n",
      "Epoch 398/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1024 - acc: 0.9584\n",
      "Epoch 399/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1111 - acc: 0.9597\n",
      "Epoch 400/400\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.1064 - acc: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e4a065828>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(normalize(train_data),train_labels,batch_size=1, epochs=400, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1425788402557373, 0.943877637386322]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(normalize(test_data), test_labels, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"opticflow-optimized3.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"opticflow-optimized3.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 94.39%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "# load YAML and create model\n",
    "yaml_file = open('opticflow-optimized3.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"opticflow-optimized3.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='MSE', optimizer=opti, metrics=['accuracy'])\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(test_data, test_labels, verbose=0)\n",
    "score = loaded_model.evaluate(normalize(test_data), test_labels, verbose=0)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "light\n",
      "light\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "light\n",
      "light\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "light\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "unknown\n",
      "unknown\n",
      "-----------------------------------------------\n",
      "unknown\n",
      "unknown\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "light\n",
      "unknown\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "rot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "light\n",
      "light\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "move\n",
      "move\n",
      "-----------------------------------------------\n",
      "frot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "frot\n",
      "rot\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n",
      "frot\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "light\n",
      "-----------------------------------------------\n",
      "frot\n",
      "frot\n",
      "-----------------------------------------------\n",
      "dynamiclight\n",
      "dynamiclight\n",
      "-----------------------------------------------\n",
      "static\n",
      "static\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "definition = ['static', 'move', 'rot', 'frot', 'light', 'dynamiclight','unknown']\n",
    "\n",
    "for test_num in range (50):\n",
    "    lol = normalize(train_data[test_num].reshape(1,-1))\n",
    "    lol_label = train_labels[test_num]\n",
    "    # print(lol.shape)\n",
    "    # print(lol, lol_label)\n",
    "    prediction = loaded_model.predict(lol.reshape(1,10))\n",
    "    print(definition[np.argmax(prediction[0])])\n",
    "    print(definition[np.argmax(lol_label)])\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kv2It0UYTBq7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BUFFER_SIZE = 100\n",
    "WIDTH = 1280\n",
    "HEIGHT = 720\n",
    "video_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UMWqnsH9TBrC"
   },
   "outputs": [],
   "source": [
    "def calculate_n_of_hsv(frame_sq,n):\n",
    "    sum_n = 0\n",
    "    var_n = 0\n",
    "    for frame in frame_sq:\n",
    "        var_n += np.var(frame[:,:,n])# / (np.mean(frame[:,:,n]) * 1\n",
    "        sum_n += np.sum(frame[:,:,n])\n",
    "\n",
    "    avg_n = sum_n/ (len(frame_sq) * frame_sq[0].shape[0] * frame_sq[0].shape[1])\n",
    "    return np.array([avg_n ,var_n])\n",
    "def calculate_comp(frame_sq):\n",
    "    sum_comp = 0\n",
    "    for i in range(len(frame_sq)):\n",
    "        if(i != 0):\n",
    "            sum_comp += compare_img(frame_sq[i], frame_sq[i-1])\n",
    "#         if(i == 1): print(compare_img(frame_sq[i], frame_sq[i-1]))\n",
    "    sum_comp /= (len(frame_sq) - 1)\n",
    "    return sum_comp\n",
    "def calculate_opticFlow(frame_sq):\n",
    "    prvs = cv2.resize(frame_sq[0],(0,0),fx=0.5,fy=0.5)\n",
    "    mag_sum = 0\n",
    "    ang_sum = 0\n",
    "    var_mag = 0\n",
    "    var_ang = 0\n",
    "    for i in range(1,len(frame_sq)):\n",
    "        frame2 = frame_sq[i]\n",
    "        next = cv2.resize(frame2, (0,0), fx=0.5, fy=0.5) \n",
    "        flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        mag = cv2.normalize(mag,None,0,1,cv2.NORM_MINMAX)\n",
    "        ang = np.absolute(cv2.normalize(ang,None,-1,1,cv2.NORM_MINMAX))\n",
    "        mag_sum = np.sum(mag)\n",
    "        ang_sum = np.sum(ang)\n",
    "        var_mag += np.var(mag)\n",
    "        var_ang += np.var(ang)\n",
    "    mag_sum /= (BUFFER_SIZE * WIDTH * HEIGHT)\n",
    "    ang_sum /= (BUFFER_SIZE * WIDTH * HEIGHT)\n",
    "    var_mag /= BUFFER_SIZE\n",
    "    var_ang /= BUFFER_SIZE\n",
    "    return np.array([mag_sum, ang_sum, var_mag, var_ang])\n",
    "def calculate_opticflow_of_pair(prvs,next):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "def calculate_opticflow_final(sq):\n",
    "    mag_sum = 0\n",
    "    ang_sum = 0\n",
    "    var_mag = 0\n",
    "    var_ang = 0\n",
    "    for flow in sq:\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        mag = cv2.normalize(mag,None,0,1,cv2.NORM_MINMAX)\n",
    "        ang = np.absolute(cv2.normalize(ang,None,-1,1,cv2.NORM_MINMAX))\n",
    "        mag_sum = np.sum(mag)\n",
    "        ang_sum = np.sum(ang)\n",
    "        var_mag += np.var(mag)\n",
    "        var_ang += np.var(ang)\n",
    "    mag_sum /= (BUFFER_SIZE * WIDTH * HEIGHT)\n",
    "    ang_sum /= (BUFFER_SIZE * WIDTH * HEIGHT)\n",
    "    var_mag /= BUFFER_SIZE\n",
    "    var_ang /= BUFFER_SIZE\n",
    "    return np.array([mag_sum, ang_sum, var_mag, var_ang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_img(img1,img2):\n",
    "    img1 = normalize_gray(img1)\n",
    "    img2 = normalize_gray(img2)\n",
    "    diff = img1 - img2\n",
    "    m_norm = np.sum(abs(diff))\n",
    "#     return m_norm\n",
    "    return 0\n",
    "def normalize_frame(frame):\n",
    "    return frame/255\n",
    "\n",
    "def normalize_gray(frame):\n",
    "    rng = np.max(frame) - np.min(frame)\n",
    "    amin = np.min(frame)\n",
    "    return (frame-amin)/rng #range from [0,1]\n",
    "def createDataset(data):\n",
    "    dataset = data[0].copy()\n",
    "    data.remove(data[0])\n",
    "    for datum in data:\n",
    "        dataset = np.append(dataset, datum, axis = 1)\n",
    "    return dataset\n",
    "def createTSV(dataset,filename):\n",
    "    dataset = (dataset.copy()).astype(str)\n",
    "#     datasetName = \"dataset\" + str(dataset_no) + \".tsv\"\n",
    "    datasetName = filename + \".tsv\"\n",
    "    file = open(datasetName, \"w\")\n",
    "#     file.write(\"h\\ts\\tv\\tframe_edges_comp\\tframe_comp\\n\")\n",
    "    for i in range(dataset.shape[0]):\n",
    "        file.write(\"\\t\".join(dataset[i,:].tolist()))\n",
    "        file.write(\"\\n\")\n",
    "#         if(i + 1 != dataset.shape[0]):\n",
    "#             file.write(\"\\n\")\n",
    "    file.close()\n",
    "    return\n",
    "def createTSVLabel(dataset,filename):\n",
    "    dataset = (dataset.copy()).astype(str)\n",
    "#     datasetName = \"label\" + str(dataset_no) + \".tsv\"\n",
    "    datasetName = filename\n",
    "    file = open(datasetName, \"w\")\n",
    "    file.write(\"havg\\thv\\tsavg\\tsv\\tvavg\\tvv\\tmagavg\\tmagv\\tangavg\\tangv\\n\")\n",
    "    for i in range(dataset.shape[0]):\n",
    "        file.write(\"\\t\".join(dataset[i,:].tolist()))\n",
    "        file.write(\"\\n\")\n",
    "#         if(i + 1 != dataset.shape[0]):\n",
    "#             file.write(\"\\n\")\n",
    "    file.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(frame):\n",
    "#     print(\"input: \", frame)\n",
    "    new_frame = scaler.transform(frame.reshape(1,-1))\n",
    "#     new_frame = frame.reshape(1,-1)\n",
    "#     print(\"output: \",new_frame)\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(frame_sq,frame_sq_gray):\n",
    "def process(frame_sq, opticflow_results):\n",
    "    h = calculate_n_of_hsv(frame_sq,0)\n",
    "    s = calculate_n_of_hsv(frame_sq,1)\n",
    "    v = calculate_n_of_hsv(frame_sq,2)\n",
    "#     opticFlow = calculate_opticFlow(frame_sq_gray)\n",
    "    opticFlow = calculate_opticflow_final(opticflow_results)\n",
    "    return _normalize(np.append(h,np.append(s,np.append(v,opticFlow))))\n",
    "def predict(output):\n",
    "    prediction = loaded_model.predict(output)\n",
    "    print(\"confidence: \" + str(prediction))\n",
    "    return(definition[np.argmax(prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence: [[1.1365470e-01 8.8634533e-01 3.5092951e-16 5.1205318e-10 9.4463881e-12\n",
      "  5.3815535e-10 2.9981723e-10]]\n",
      "moveconfidence: [[8.4545112e-01 1.5454888e-01 9.9942683e-18 1.7168629e-11 1.6149536e-13\n",
      "  3.4166877e-12 5.2280827e-12]]\n",
      "staticconfidence: [[4.0452200e-05 9.9794918e-01 4.8322065e-08 1.9658937e-03 1.3298215e-08\n",
      "  1.1530257e-06 4.3256361e-05]]\n",
      "moveconfidence: [[4.78829793e-18 4.58741124e-05 1.44960005e-02 5.37114143e-01\n",
      "  4.24719229e-03 3.86749834e-01 5.73469177e-02]]\n",
      "frotconfidence: [[1.0000000e+00 7.0573383e-36 3.1424890e-31 1.0590995e-22 0.0000000e+00\n",
      "  0.0000000e+00 4.5065966e-31]]\n",
      "staticconfidence: [[1.0000000e+00 4.3095435e-20 1.9618734e-24 2.1276858e-16 0.0000000e+00\n",
      "  0.0000000e+00 4.2181856e-27]]\n",
      "staticconfidence: [[1.9963609e-17 4.7132107e-07 2.7854532e-01 7.2136247e-01 4.7185200e-08\n",
      "  2.1494566e-07 9.1512651e-05]]\n",
      "frotconfidence: [[3.2565547e-14 1.7252846e-01 1.0845958e-01 7.1678752e-01 3.9002084e-06\n",
      "  1.1114840e-03 1.1090107e-03]]\n",
      "frotconfidence: [[5.9265028e-12 2.1332771e-02 1.6074145e-02 9.4570571e-01 1.6723441e-04\n",
      "  5.1149162e-03 1.1605314e-02]]\n",
      "frotconfidence: [[1.04081098e-13 5.32717706e-07 4.31207067e-04 3.01285088e-02\n",
      "  2.94931561e-01 5.63742280e-01 1.10765904e-01]]\n",
      "dynamiclightconfidence: [[1.3524936e-02 3.3580053e-01 4.0251905e-08 1.3005314e-03 1.4647000e-01\n",
      "  4.6382520e-01 3.9078824e-02]]\n",
      "dynamiclightconfidence: [[3.7001623e-04 1.4112876e-01 3.8648810e-08 7.7884528e-04 1.3584372e-01\n",
      "  6.9635212e-01 2.5526490e-02]]\n",
      "dynamiclightconfidence: [[1.2979859e-03 2.1098515e-01 1.7969141e-08 5.5286079e-04 1.2366535e-01\n",
      "  6.4073652e-01 2.2762092e-02]]\n",
      "dynamiclightconfidence: [[3.4209125e-04 9.9056810e-01 9.9041586e-07 1.2446512e-03 3.4629824e-04\n",
      "  6.0891206e-03 1.4087493e-03]]\n",
      "moveconfidence: [[5.0747114e-01 3.1044796e-01 7.2705603e-05 1.7044678e-01 1.1457636e-05\n",
      "  4.8292441e-05 1.1501661e-02]]\n",
      "staticconfidence: [[9.4529605e-01 5.4389935e-02 1.8178147e-08 3.0156117e-04 3.3491794e-08\n",
      "  4.9663722e-08 1.2467279e-05]]\n",
      "staticconfidence: [[9.6980894e-01 3.0187497e-02 2.5179764e-10 3.4795830e-06 2.9783542e-10\n",
      "  9.3303620e-10 1.3223624e-07]]\n",
      "staticconfidence: [[3.0780789e-06 9.9984562e-01 7.1285605e-08 1.3059172e-04 1.7023399e-07\n",
      "  1.1526367e-05 8.8167535e-06]]\n",
      "moveconfidence: [[4.1617497e-04 7.9824328e-01 1.8973122e-07 3.7041942e-03 1.6033541e-02\n",
      "  1.5912603e-01 2.2476466e-02]]\n",
      "moveconfidence: [[2.0415562e-03 1.2107556e-01 1.6360741e-07 5.4024993e-03 1.5999337e-01\n",
      "  5.9463155e-01 1.1685534e-01]]\n",
      "dynamiclightconfidence: [[9.9999964e-01 3.8924108e-07 1.3768852e-15 1.8419651e-09 1.5614890e-12\n",
      "  2.4172396e-13 6.0886668e-10]]\n",
      "staticconfidence: [[1.3205552e-05 3.6740625e-05 9.8806352e-04 9.8629564e-01 7.9256669e-04\n",
      "  8.4772219e-06 1.1865337e-02]]\n",
      "frotconfidence: [[1.3730155e-12 4.6189307e-12 4.9456245e-05 1.2674535e-03 9.8813558e-01\n",
      "  1.5648879e-03 8.9825653e-03]]\n",
      "lightconfidence: [[8.8457962e-27 3.8576326e-22 2.4574329e-09 2.7707147e-08 9.9853396e-01\n",
      "  1.4170760e-03 4.8955771e-05]]\n",
      "lightconfidence: [[7.6937042e-17 3.7546340e-18 2.6978564e-09 1.3214999e-06 9.9871337e-01\n",
      "  3.4123904e-04 9.4415119e-04]]\n",
      "lightconfidence: [[5.9026826e-23 2.6568828e-18 8.6651353e-10 8.6208107e-09 9.9516833e-01\n",
      "  4.8175035e-03 1.4268190e-05]]\n",
      "lightconfidence: [[1.0666590e-12 1.5356565e-10 1.6068156e-05 1.2233141e-03 9.8860639e-01\n",
      "  3.8912524e-03 6.2629823e-03]]\n",
      "lightconfidence: [[3.4024913e-17 5.1753254e-06 3.4100938e-07 3.7151462e-05 6.2179472e-02\n",
      "  9.3736070e-01 4.1717422e-04]]\n",
      "dynamiclightconfidence: [[8.8363622e-11 9.9967790e-01 8.6940317e-06 3.1342093e-04 4.3746816e-12\n",
      "  1.6230563e-10 5.0332378e-09]]\n",
      "moveconfidence: [[8.2358564e-26 1.8754695e-04 1.0634687e-01 2.9990248e-02 2.0039701e-03\n",
      "  8.6117762e-01 2.9371277e-04]]\n",
      "dynamiclightconfidence: [[2.39050932e-20 3.01213021e-07 1.10114925e-01 6.23760223e-01\n",
      "  9.09494385e-02 1.48826569e-01 2.63485350e-02]]\n",
      "frotconfidence: [[4.0991467e-11 1.2435626e-07 4.0810429e-03 8.2619613e-01 4.9378961e-02\n",
      "  1.8283050e-03 1.1851553e-01]]\n",
      "frotconfidence: [[2.1354547e-08 5.1055005e-05 1.6914580e-02 9.5004934e-01 6.7211390e-03\n",
      "  4.6037100e-04 2.5803445e-02]]\n",
      "frotconfidence: [[2.8301574e-07 3.1373063e-05 2.0965161e-03 9.9702257e-01 9.7518296e-07\n",
      "  7.8272443e-08 8.4810291e-04]]\n",
      "frotconfidence: [[1.8576019e-20 1.8545808e-14 5.2421412e-04 4.9061957e-03 9.7064990e-01\n",
      "  7.8499317e-03 1.6069701e-02]]\n",
      "lightconfidence: [[9.4833632e-21 3.7745168e-10 1.3351793e-03 2.6041861e-03 6.9517058e-01\n",
      "  2.9600194e-01 4.8881276e-03]]\n",
      "lightconfidence: [[3.9721009e-09 4.1417522e-10 6.3161727e-04 9.9753928e-01 2.5432223e-06\n",
      "  4.1809156e-09 1.8266614e-03]]\n",
      "frotconfidence: [[2.9894436e-02 1.2206261e-02 4.1692771e-04 9.4397509e-01 2.0431652e-04\n",
      "  1.2646190e-05 1.3290306e-02]]\n",
      "frotconfidence: [[5.1539991e-23 9.0963425e-24 2.8263718e-09 3.0795033e-07 9.9964035e-01\n",
      "  3.3948698e-05 3.2535550e-04]]\n",
      "lightconfidence: [[3.7748969e-21 2.6734244e-14 3.7839659e-04 3.0286657e-03 9.6657056e-01\n",
      "  1.6261155e-02 1.3761207e-02]]\n",
      "lightconfidence: [[1.5179458e-21 3.1299141e-22 6.4825190e-07 1.7153670e-05 9.9826461e-01\n",
      "  2.6768716e-05 1.6908421e-03]]\n",
      "lightconfidence: [[2.1350145e-10 1.3463999e-11 1.4057026e-04 5.4342587e-02 7.0380557e-01\n",
      "  1.3163767e-03 2.4039488e-01]]\n",
      "lightconfidence: [[9.7212571e-01 4.5372862e-03 8.8094708e-08 7.7702031e-03 1.0061045e-03\n",
      "  2.3091670e-04 1.4329627e-02]]\n",
      "staticconfidence: [[2.3636367e-02 8.4241241e-01 1.5518525e-08 5.9830479e-04 1.9051798e-02\n",
      "  1.0379446e-01 1.0506622e-02]]\n",
      "moveconfidence: [[5.9376508e-02 8.1507266e-01 1.3078592e-08 7.2355126e-04 2.0855131e-02\n",
      "  9.0830117e-02 1.3142073e-02]]\n",
      "moveconfidence: [[3.4436774e-02 7.9689223e-01 1.6067814e-08 7.9227384e-04 2.6679037e-02\n",
      "  1.2608355e-01 1.5116131e-02]]\n",
      "moveconfidence: [[6.9082045e-04 6.6144848e-01 3.2689730e-08 6.3877500e-04 3.1798676e-02\n",
      "  2.9424256e-01 1.1180699e-02]]\n",
      "moveconfidence: [[1.2124211e-01 7.7622151e-01 1.8574646e-08 1.1130397e-03 1.8501554e-02\n",
      "  6.6406325e-02 1.6515313e-02]]\n",
      "moveconfidence: [[7.3981225e-02 7.7677214e-01 2.3411094e-08 1.3622488e-03 2.6098374e-02\n",
      "  1.0028716e-01 2.1498766e-02]]\n",
      "moveconfidence: [[9.6299298e-02 7.8146976e-01 2.0274651e-08 1.1260866e-03 2.1171410e-02\n",
      "  8.2069136e-02 1.7864348e-02]]\n",
      "moveconfidence: [[1.7090332e-03 9.7370309e-01 1.1300269e-06 9.0207439e-03 1.2763967e-03\n",
      "  6.8625351e-03 7.4269874e-03]]\n",
      "moveconfidence: [[9.2576212e-01 6.5000907e-02 7.3633288e-08 2.8768675e-03 6.9970847e-04\n",
      "  4.8336247e-04 5.1769195e-03]]\n",
      "static"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "frame_sq = []\n",
    "frame_sq_gray = []\n",
    "opticflow_buffer = []\n",
    "opticflow_results = []\n",
    "BUFFER_SIZE = 100\n",
    "# cap = cv2.VideoCapture(\"../doit3/5.avi\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "video_count = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)  \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    opticflow_buffer.append(cv2.resize(gray, (0,0), fx=0.5, fy=0.5))\n",
    "    if(len(opticflow_buffer) == 2):\n",
    "        opticflow_results.append(calculate_opticflow_of_pair(opticflow_buffer[0], opticflow_buffer[1]))\n",
    "        del opticflow_buffer[0]\n",
    "    if(video_count == 0):\n",
    "        WIDTH = int(cap.get(3))\n",
    "        HEIGHT = int(cap.get(4))\n",
    "        video_count += 1\n",
    "    frame_sq.append(normalize_frame(hsv))\n",
    "#     frame_sq_gray.append(normalize_frame(gray))\n",
    "    if(len(frame_sq) >= BUFFER_SIZE):\n",
    "#         output = process(frame_sq, frame_sq_gray)\n",
    "        output = process(frame_sq, opticflow_results)\n",
    "        predictt = predict(output)\n",
    "        sys.stdout.write(\"\\r\" + predictt)\n",
    "        sys.stdout.flush()        \n",
    "#         del frame_sq[0]\n",
    "        frame_sq = []\n",
    "        frame_sq_gray = []\n",
    "        opticflow_buffer = []\n",
    "        opticflow_results = []\n",
    "#         break\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = ['static', 'move', 'rot', 'frot', 'light', 'dynamiclight','unknown']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
